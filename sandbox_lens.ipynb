{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64a7eb1708070083",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T10:41:00.041179Z",
     "start_time": "2024-09-01T10:40:49.783052Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tok/miniconda3/envs/lens/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from diffusers_wrapper import StableDiffusion3TextToImage, FluxTextToImage, StableDiffusion2TextToImage, StableDiffusionXLPipelineTextToImage\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c4d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 4\n",
    "main_output_path = 'output'\n",
    "model_name = 'flux-schnell' # 'sd2' or 'sd3' or 'sdxl' or 'flux-dev' or 'flux-schnell'\n",
    "max_sequence_lengths ={\n",
    "    'sd2': 77,\n",
    "    'sd3': 77,\n",
    "    'sdxl': 256,\n",
    "    'flux-dev': 512,\n",
    "    'flux-schnell': 256\n",
    "}\n",
    "max_sequence_length = max_sequence_lengths[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25b9447f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.32it/s]it/s]\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:02<00:00,  3.26it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if 'flux' in model_name:\n",
    "    ckpt_dir = ''\n",
    "    model_class = FluxTextToImage(model_name=model_name, ckpt_dir=ckpt_dir, num_images=num_images, \n",
    "                                  max_sequence_length=max_sequence_length)\n",
    "elif model_name == 'sd2':\n",
    "    model_name = model_name\n",
    "    ckpt_dir = ''\n",
    "    model_class = StableDiffusion2TextToImage(model_name=model_name, ckpt_dir=ckpt_dir, num_images=num_images)\n",
    "elif model_name == 'sd3':\n",
    "    model_name = model_name\n",
    "    ckpt_dir = ''\n",
    "    model_class = StableDiffusion3TextToImage(model_name=model_name, ckpt_dir=ckpt_dir, num_images=num_images, \n",
    "                                              max_sequence_length=max_sequence_length) \n",
    "elif model_name == 'sdxl':\n",
    "    model_name = model_name\n",
    "    ckpt_dir = ''\n",
    "    model_class = StableDiffusionXLPipelineTextToImage(model_name=model_name, ckpt_dir=ckpt_dir, num_images=num_images, \n",
    "                                                       max_sequence_length=max_sequence_length)\n",
    "else:\n",
    "    raise ValueError(\"Model name not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "379899c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 kids\n",
      "1 playing\n",
      "2 in\n",
      "3 the\n",
      "4 play\n",
      "5 ground\n",
      "6 </s>\n"
     ]
    }
   ],
   "source": [
    "skip_layers = 0\n",
    "return_grids = True\n",
    "# full is the full range of tokens with padas - remove if you dont need images from this range\n",
    "# tokens is the range of tokens without padas - remove if you dont need images from this range\n",
    "# specific_tokens - if you want images from specific tokens, \n",
    "ranges_to_keep = ['full', 'tokens', 'specific_token_idx_to_keep_per_prompt']\n",
    "\n",
    "prompts = [\n",
    "    'kids playing in the play ground',\n",
    "]\n",
    "\n",
    "tokenizers = model_class.get_tokenizers()\n",
    "tokenizer_3 = tokenizers['tokenizer_2']\n",
    "tokenized_prompts = [tokenizer_3.encode(prompt) for prompt in prompts]\n",
    "for prompt in tokenized_prompts:\n",
    "    for subtoken_idx, subtoken in enumerate(tokenized_prompts[0]):\n",
    "        print(subtoken_idx, tokenizer_3.decode(subtoken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0546e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# each list would results in generating images fro, the tokens in the list only. If you want to generate image from each prompt, pass a list for each prompt\n",
    "# specific_tokens_per_prompt = [\n",
    "#     ['kids', 'in']\n",
    "# ]\n",
    "\n",
    "specific_token_idx_to_keep_per_prompt = [\n",
    "    [5]\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38fef12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating images for prompt: kids playing in the play ground\n",
      "Validated skip_layers: [0, 0]\n",
      "ranges_to_keep ['full', 'tokens', 'specific_token_idx_to_keep_per_prompt']\n",
      "Getting range for full\n",
      "Getting range for tokens\n",
      "Getting range for specific_token_idx_to_keep_per_prompt\n",
      "st_ground: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255]\n",
      "text_ids shape [tokenizer - CLIP]:  torch.Size([1, 77])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original CLIP pooling code\n",
      "text_ids shape [tokenizer_2 - T5]:  torch.Size([1, 256])\n",
      "Skiping num layers:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:02<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image grid for 4 images\n",
      "Image grid saved to output/flux-schnell/kids playing in the play ground/full/full_[0, 0].png\n",
      "text_ids shape [tokenizer - CLIP]:  torch.Size([1, 77])\n",
      "Original CLIP pooling code\n",
      "text_ids shape [tokenizer_2 - T5]:  torch.Size([1, 256])\n",
      "Skiping num layers:  0\n",
      "skip_tokens (T5):  [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255]\n",
      "replacing 7 replacing 8 replacing 9 replacing 10 replacing 11 replacing 12 replacing 13 replacing 14 replacing 15 replacing 16 replacing 17 replacing 18 replacing 19 replacing 20 replacing 21 replacing 22 replacing 23 replacing 24 replacing 25 replacing 26 replacing 27 replacing 28 replacing 29 replacing 30 replacing 31 replacing 32 replacing 33 replacing 34 replacing 35 replacing 36 replacing 37 replacing 38 replacing 39 replacing 40 replacing 41 replacing 42 replacing 43 replacing 44 replacing 45 replacing 46 replacing 47 replacing 48 replacing 49 replacing 50 replacing 51 replacing 52 replacing 53 replacing 54 replacing 55 replacing 56 replacing 57 replacing 58 replacing 59 replacing 60 replacing 61 replacing 62 replacing 63 replacing 64 replacing 65 replacing 66 replacing 67 replacing 68 replacing 69 replacing 70 replacing 71 replacing 72 replacing 73 replacing 74 replacing 75 replacing 76 replacing 77 replacing 78 replacing 79 replacing 80 replacing 81 replacing 82 replacing 83 replacing 84 replacing 85 replacing 86 replacing 87 replacing 88 replacing 89 replacing 90 replacing 91 replacing 92 replacing 93 replacing 94 replacing 95 replacing 96 replacing 97 replacing 98 replacing 99 replacing 100 replacing 101 replacing 102 replacing 103 replacing 104 replacing 105 replacing 106 replacing 107 replacing 108 replacing 109 replacing 110 replacing 111 replacing 112 replacing 113 replacing 114 replacing 115 replacing 116 replacing 117 replacing 118 replacing 119 replacing 120 replacing 121 replacing 122 replacing 123 replacing 124 replacing 125 replacing 126 replacing 127 replacing 128 replacing 129 replacing 130 replacing 131 replacing 132 replacing 133 replacing 134 replacing 135 replacing 136 replacing 137 replacing 138 replacing 139 replacing 140 replacing 141 replacing 142 replacing 143 replacing 144 replacing 145 replacing 146 replacing 147 replacing 148 replacing 149 replacing 150 replacing 151 replacing 152 replacing 153 replacing 154 replacing 155 replacing 156 replacing 157 replacing 158 replacing 159 replacing 160 replacing 161 replacing 162 replacing 163 replacing 164 replacing 165 replacing 166 replacing 167 replacing 168 replacing 169 replacing 170 replacing 171 replacing 172 replacing 173 replacing 174 replacing 175 replacing 176 replacing 177 replacing 178 replacing 179 replacing 180 replacing 181 replacing 182 replacing 183 replacing 184 replacing 185 replacing 186 replacing 187 replacing 188 replacing 189 replacing 190 replacing 191 replacing 192 replacing 193 replacing 194 replacing 195 replacing 196 replacing 197 replacing 198 replacing 199 replacing 200 replacing 201 replacing 202 replacing 203 replacing 204 replacing 205 replacing 206 replacing 207 replacing 208 replacing 209 replacing 210 replacing 211 replacing 212 replacing 213 replacing 214 replacing 215 replacing 216 replacing 217 replacing 218 replacing 219 replacing 220 replacing 221 replacing 222 replacing 223 replacing 224 replacing 225 replacing 226 replacing 227 replacing 228 replacing 229 replacing 230 replacing 231 replacing 232 replacing 233 replacing 234 replacing 235 replacing 236 replacing 237 replacing 238 replacing 239 replacing 240 replacing 241 replacing 242 replacing 243 replacing 244 replacing 245 replacing 246 replacing 247 replacing 248 replacing 249 replacing 250 replacing 251 replacing 252 replacing 253 replacing 254 replacing 255 Keep token_idx:  0 Keep token_idx:  1 Keep token_idx:  2 Keep token_idx:  3 Keep token_idx:  4 Keep token_idx:  5 Keep token_idx:  6 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image grid for 4 images\n",
      "Image grid saved to output/flux-schnell/kids playing in the play ground/tokens/tokens_[0, 0].png\n",
      "text_ids shape [tokenizer - CLIP]:  torch.Size([1, 77])\n",
      "Original CLIP pooling code\n",
      "text_ids shape [tokenizer_2 - T5]:  torch.Size([1, 256])\n",
      "Skiping num layers:  0\n",
      "skip_tokens (T5):  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255]\n",
      "replacing 0 replacing 1 replacing 2 replacing 3 replacing 4 replacing 5 replacing 6 replacing 7 replacing 8 replacing 9 replacing 10 replacing 11 replacing 12 replacing 13 replacing 14 replacing 15 replacing 16 replacing 17 replacing 18 replacing 19 replacing 20 replacing 21 replacing 22 replacing 23 replacing 24 replacing 25 replacing 26 replacing 27 replacing 28 replacing 29 replacing 30 replacing 31 replacing 32 replacing 33 replacing 34 replacing 35 replacing 36 replacing 37 replacing 38 replacing 39 replacing 40 replacing 41 replacing 42 replacing 43 replacing 44 replacing 45 replacing 46 replacing 47 replacing 48 replacing 49 replacing 50 replacing 51 replacing 52 replacing 53 replacing 54 replacing 55 replacing 56 replacing 57 replacing 58 replacing 59 replacing 60 replacing 61 replacing 62 replacing 63 replacing 64 replacing 65 replacing 66 replacing 67 replacing 68 replacing 69 replacing 70 replacing 71 replacing 72 replacing 73 replacing 74 replacing 75 replacing 76 replacing 77 replacing 78 replacing 79 replacing 80 replacing 81 replacing 82 replacing 83 replacing 84 replacing 85 replacing 86 replacing 87 replacing 88 replacing 89 replacing 90 replacing 91 replacing 92 replacing 93 replacing 94 replacing 95 replacing 96 replacing 97 replacing 98 replacing 99 replacing 100 replacing 101 replacing 102 replacing 103 replacing 104 replacing 105 replacing 106 replacing 107 replacing 108 replacing 109 replacing 110 replacing 111 replacing 112 replacing 113 replacing 114 replacing 115 replacing 116 replacing 117 replacing 118 replacing 119 replacing 120 replacing 121 replacing 122 replacing 123 replacing 124 replacing 125 replacing 126 replacing 127 replacing 128 replacing 129 replacing 130 replacing 131 replacing 132 replacing 133 replacing 134 replacing 135 replacing 136 replacing 137 replacing 138 replacing 139 replacing 140 replacing 141 replacing 142 replacing 143 replacing 144 replacing 145 replacing 146 replacing 147 replacing 148 replacing 149 replacing 150 replacing 151 replacing 152 replacing 153 replacing 154 replacing 155 replacing 156 replacing 157 replacing 158 replacing 159 replacing 160 replacing 161 replacing 162 replacing 163 replacing 164 replacing 165 replacing 166 replacing 167 replacing 168 replacing 169 replacing 170 replacing 171 replacing 172 replacing 173 replacing 174 replacing 175 replacing 176 replacing 177 replacing 178 replacing 179 replacing 180 replacing 181 replacing 182 replacing 183 replacing 184 replacing 185 replacing 186 replacing 187 replacing 188 replacing 189 replacing 190 replacing 191 replacing 192 replacing 193 replacing 194 replacing 195 replacing 196 replacing 197 replacing 198 replacing 199 replacing 200 replacing 201 replacing 202 replacing 203 replacing 204 replacing 205 replacing 206 replacing 207 replacing 208 replacing 209 replacing 210 replacing 211 replacing 212 replacing 213 replacing 214 replacing 215 replacing 216 replacing 217 replacing 218 replacing 219 replacing 220 replacing 221 replacing 222 replacing 223 replacing 224 replacing 225 replacing 226 replacing 227 replacing 228 replacing 229 replacing 230 replacing 231 replacing 232 replacing 233 replacing 234 replacing 235 replacing 236 replacing 237 replacing 238 replacing 239 replacing 240 replacing 241 replacing 242 replacing 243 replacing 244 replacing 245 replacing 246 replacing 247 replacing 248 replacing 249 replacing 250 replacing 251 replacing 252 replacing 253 replacing 254 replacing 255 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image grid for 4 images\n",
      "Image grid saved to output/flux-schnell/kids playing in the play ground/st_ground/st_ground_[0, 0].png\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "for prompt, specific_tokens in zip(prompts, specific_token_idx_to_keep_per_prompt):\n",
    "    print(\"generating images for prompt:\", prompt)         \n",
    "    output_path = f'{main_output_path}/{model_name}/{prompt}'\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    if 'flux' in model_name:\n",
    "        grids = model_class.forward(prompt, num_images=model_class.num_images, \n",
    "                    output_path=output_path, \n",
    "                    save_grid=True, \n",
    "                    save_per_image=False, \n",
    "                    return_grids=return_grids,\n",
    "                    skip_layers=skip_layers,\n",
    "                    ranges_to_keep=ranges_to_keep,\n",
    "                    specific_token_idx_to_keep_per_prompt=specific_token_idx_to_keep_per_prompt,\n",
    "                    # specific_tokens=specific_tokens,\n",
    "                    # pad_encoders=pad_encoders,\n",
    "                    # zero_paddings=False, \n",
    "                    # replace_with_pads=True,\n",
    "                    # turn_attention_off=False,\n",
    "                    )\n",
    "    else:\n",
    "        pad_encoders = [1,2] # 1,2 for clips, 3 for T5\n",
    "        grids = model_class.forward(prompt, num_images=model_class.num_images, \n",
    "                            output_path=output_path, \n",
    "                            save_grid=True, \n",
    "                            save_per_image=False, \n",
    "                            return_grids=return_grids,\n",
    "                            skip_layers=skip_layers,\n",
    "                            ranges_to_keep=ranges_to_keep,\n",
    "                            specific_token_idx_to_keep_per_prompt=specific_token_idx_to_keep_per_prompt,\n",
    "                            # specific_tokens=specific_tokens,\n",
    "                            pad_encoders=pad_encoders,\n",
    "                            # zero_paddings=False, \n",
    "                            # replace_with_pads=True,\n",
    "                            # turn_attention_off=False,\n",
    "                            )\n",
    "    # print(\"done generating images for prompt:\", prompt)\n",
    "    # for grid in grids:\n",
    "    #     grid.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de70af03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
